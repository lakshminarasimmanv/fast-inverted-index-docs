"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[8133],{3260:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"ltr","title":"LTR","description":"The fast-inverted-index library now supports a Learning to Rank (LTR) approach to document scoring and retrieval, providing more flexibility and potentially better results than traditional TF-IDF and BM25 scoring methods.","source":"@site/docs/ltr.md","sourceDirName":".","slug":"/ltr","permalink":"/fast-inverted-index-docs/docs/ltr","draft":false,"unlisted":false,"editUrl":"https://github.com/username/fast-inverted-index/tree/main/docusaurus/docs/ltr.md","tags":[],"version":"current","frontMatter":{"id":"ltr","title":"LTR","sidebar_label":"LTR"},"sidebar":"docs","previous":{"title":"Configuration","permalink":"/fast-inverted-index-docs/docs/configuration"},"next":{"title":"BM25L","permalink":"/fast-inverted-index-docs/docs/bm25l"}}');var r=t(4848),s=t(8453);const a={id:"ltr",title:"LTR",sidebar_label:"LTR"},o="Learning to Rank (LTR)",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Using LTR",id:"using-ltr",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"Features Used in LTR Scoring",id:"features-used-in-ltr-scoring",level:3},{value:"Customizing Field Boosts",id:"customizing-field-boosts",level:3},{value:"Advanced: Feature Extraction for Custom Models",id:"advanced-feature-extraction-for-custom-models",level:2},{value:"How LTR Works Internally",id:"how-ltr-works-internally",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Future Directions",id:"future-directions",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"learning-to-rank-ltr",children:"Learning to Rank (LTR)"})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"fast-inverted-index"})," library now supports a Learning to Rank (LTR) approach to document scoring and retrieval, providing more flexibility and potentially better results than traditional TF-IDF and BM25 scoring methods."]}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Learning to Rank is a machine learning technique that uses multiple features to score and rank documents for a given query. Unlike traditional scoring methods like TF-IDF and BM25 which use fixed formulas, LTR can:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Combine multiple signals (features) with learned weights"}),"\n",(0,r.jsx)(n.li,{children:"Adapt to specific user preferences and search patterns"}),"\n",(0,r.jsx)(n.li,{children:"Incorporate domain-specific relevance signals"}),"\n",(0,r.jsx)(n.li,{children:"Improve over time with feedback"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The current LTR implementation in ",(0,r.jsx)(n.code,{children:"fast-inverted-index"})," provides:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"A linear model that combines multiple features with configurable weights"}),"\n",(0,r.jsx)(n.li,{children:"Feature extraction functionality to support training external ML models"}),"\n",(0,r.jsx)(n.li,{children:"Integration with the existing search API"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"using-ltr",children:"Using LTR"}),"\n",(0,r.jsx)(n.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,r.jsx)(n.p,{children:'Using LTR is as simple as specifying "ltr" as the ranking method:'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from fast_inverted_index import Index, RankingMethods\n\n# Create an index\nindex = Index(storage_path="path/to/index")\n\n# Add documents...\n\n# Search using LTR\nresults = index.search("query text", ranking_method="ltr")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"features-used-in-ltr-scoring",children:"Features Used in LTR Scoring"}),"\n",(0,r.jsx)(n.p,{children:"The default LTR implementation uses a linear combination of the following features:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"BM25 score"}),": The basic BM25 relevance score"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TF-IDF score"}),": The TF-IDF relevance score"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Exact match"}),": Ratio of query terms that appear in the document"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Title match"}),": How many query terms match in the title"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tag match"}),": How many query terms match in document tags"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Recency"}),": How recent the document is (newer documents score higher)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Length score"}),": Score based on document length relative to average document length"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Each feature has a configurable weight in the model."}),"\n",(0,r.jsx)(n.h3,{id:"customizing-field-boosts",children:"Customizing Field Boosts"}),"\n",(0,r.jsx)(n.p,{children:"You can influence the LTR model by providing custom field boosts:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'field_boosts = {\n    "title": 3.0,     # Higher weight for title matches\n    "tags": 2.0,      # Higher weight for tag matches\n    "content": 1.0,   # Base weight for content\n    "category": 0.8,  # Lower weight for category\n}\n\nresults = index.search("query", ranking_method="ltr", boost_fields=field_boosts)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"advanced-feature-extraction-for-custom-models",children:"Advanced: Feature Extraction for Custom Models"}),"\n",(0,r.jsx)(n.p,{children:"For advanced users who want to train their own LTR models, the library provides feature extraction capabilities:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-rust",children:'// This is available in the Rust API\nlet features = index.extract_ltr_features(&query, None)?;\n\n// Features contain term, document, and query-document interaction features\nfor feature in features {\n    println!("Doc ID: {}", feature.doc_id);\n    println!("Term features: {:?}", feature.term_features);\n    println!("Document features: {:?}", feature.doc_features);\n    println!("Interaction features: {:?}", feature.interaction_features);\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"The extracted features can be used to train custom ranking models with libraries like XGBoost, LightGBM, or scikit-learn."}),"\n",(0,r.jsx)(n.h2,{id:"how-ltr-works-internally",children:"How LTR Works Internally"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"When a query is executed with the LTR ranking method:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The index first retrieves matching documents using standard boolean retrieval"}),"\n",(0,r.jsx)(n.li,{children:"Both BM25 and TF-IDF basic scores are calculated for all matching documents"}),"\n",(0,r.jsx)(n.li,{children:"Additional features are extracted (title matches, tag matches, recency, etc.)"}),"\n",(0,r.jsx)(n.li,{children:"All features are weighted and combined into a final score"}),"\n",(0,r.jsx)(n.li,{children:"Documents are sorted by their final score"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"The default LTR model is a linear combination of features with pre-configured weights. The weights are set to provide reasonable out-of-the-box performance, but can be customized for specific use cases."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"LTR may be more computationally intensive than basic BM25 or TF-IDF as it calculates multiple features per document"}),"\n",(0,r.jsx)(n.li,{children:"For very large result sets, consider using BM25 for initial retrieval and LTR for re-ranking the top results"}),"\n",(0,r.jsx)(n.li,{children:"Feature extraction is the most expensive part of the LTR process, especially for large documents"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"future-directions",children:"Future Directions"}),"\n",(0,r.jsx)(n.p,{children:"Planned improvements for the LTR implementation include:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Support for external LTR models (e.g., ONNX format models)"}),"\n",(0,r.jsx)(n.li,{children:"User feedback integration for relevance improvements"}),"\n",(0,r.jsx)(n.li,{children:"More sophisticated features, including semantic/embedding-based features"}),"\n",(0,r.jsx)(n.li,{children:"Python API for feature extraction and model training"}),"\n",(0,r.jsx)(n.li,{children:"Click-through rate (CTR) and conversion optimization"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const r={},s=i.createContext(r);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);